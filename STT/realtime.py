from fastapi import FastAPI, WebSocket
from fastapi.middleware.cors import CORSMiddleware
from pyngrok import ngrok
import asyncio
import wave
import uuid
import os
import uvicorn
import logging

# ğŸ”§ ì™¸ë¶€ ëª¨ë“ˆ
from whisper_stt import transcribe_batch
from diarization import run_diarization
from audio_utils import split_audio_by_speaker, save_results

# â–¶ï¸ FastAPI ì•± ìƒì„±
app = FastAPI()

# âœ… CORS ì„¤ì • (React ë“± í”„ë¡ íŠ¸ì™€ í†µì‹  í—ˆìš©)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
def root():
    return {"message": "FastAPI WebSocket ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤."}

# ğŸ“¦ ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì„¤ì •
BUFFER_TIME_SECONDS = 10
CHUNK_RATE = 16000
TEMP_DIR = "temp_audio"
os.makedirs(TEMP_DIR, exist_ok=True)

@app.websocket("/ws/audio")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    print("âœ… í´ë¼ì´ì–¸íŠ¸ WebSocket ì—°ê²°ë¨")

    audio_buffer = bytearray()
    file_id = str(uuid.uuid4())
    wav_path = os.path.join(TEMP_DIR, f"{file_id}.wav")

    try:
        while True:
            data = await websocket.receive_bytes()
            print(f"ğŸ™ï¸ {len(data)}ë°”ì´íŠ¸ ì˜¤ë””ì˜¤ ìˆ˜ì‹ ë¨")
            audio_buffer.extend(data)

            if len(audio_buffer) >= CHUNK_RATE * 2 * BUFFER_TIME_SECONDS:
                print(f"ğŸ“¦ {BUFFER_TIME_SECONDS}ì´ˆ ë¶„ëŸ‰ ìˆ˜ì‹  â†’ ì €ì¥ ë° ë¶„ì„")

                with wave.open(wav_path, "wb") as wf:
                    wf.setnchannels(1)
                    wf.setsampwidth(2)
                    wf.setframerate(CHUNK_RATE)
                    wf.writeframes(audio_buffer)

                diarization_result = run_diarization(wav_path)
                speaker_segments = split_audio_by_speaker(wav_path, diarization_result)
                filepaths = [path for _, path in speaker_segments]
                transcriptions = transcribe_batch(filepaths)

                results = [
                    {"speaker": speaker, "text": text}
                    for (speaker, _), text in zip(speaker_segments, transcriptions)
                ]

                for res in results:
                    print(f"ğŸ—£ï¸ [speaker {res['speaker']}] {res['text']}")

                await websocket.send_json(results)
                print("ğŸ“¤ ê²°ê³¼ ì „ì†¡ ì™„ë£Œ")
                audio_buffer.clear()

    except Exception as e:
        print(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")
        await websocket.close()

# ğŸŸ¢ ì„œë²„ ì‹¤í–‰ + ngrok í†µí•©
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)

    # ngrok í„°ë„ ì—´ê¸°
    public_url = ngrok.connect(8000)
    print(f"ğŸŒ ì™¸ë¶€ ì ‘ì† ì£¼ì†Œ: {public_url}")
    print(f"ğŸ”Š WebSocket ì£¼ì†Œ: {public_url}/ws/audio")

    # FastAPI ì„œë²„ ì‹¤í–‰
    uvicorn.run(app, host="0.0.0.0", port=8000)
